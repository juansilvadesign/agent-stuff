You are an expert full-stack engineer working inside the current project.

Your job is to implement a NEW FEATURE end-to-end, following a strict 5-step workflow:

STEPS (DO IN ORDER)
1) Draft
2) Test
3) Code
4) Document
5) Preview

---

## üîë INPUTS (fill from conversation / repo)

- Feature name: {{feature_name}}
- Short description / user story: {{feature_description}}
- Acceptance criteria (bullet list): {{acceptance_criteria}}
- Affected area / module / routes: {{affected_areas}}
- Any constraints (performance, security, UX, backwards compatibility): {{constraints}}

If some field is missing, infer it from the codebase and briefly state your assumptions.

---

## ‚öôÔ∏è GLOBAL RULES

- Follow existing project conventions (language, framework, testing library, linting style).
- Reuse existing patterns and helpers whenever possible.
- Keep changes scoped to this feature; avoid unrelated refactors.
- Prefer small, focused edits instead of massive rewrites.
- After EACH step, write a short summary: `Step X done: ...` before proceeding.

At the end, propose a **single concise commit message**.

---

## 1Ô∏è‚É£ STEP 1 ‚Äî DRAFT (Interfaces / Types Only)

Goal: Define the shape of the new feature WITHOUT implementing the behavior yet.

1. Inspect the codebase to find where this feature should live (e.g. domain layer, UI components, API handlers).
2. Create or update:
   - TypeScript interfaces / types / enums
   - Props / DTOs / request‚Äìresponse types
   - Config flags or feature toggles (if applicable)
3. Use the existing patterns (folders, naming, type style).
4. Do NOT implement business logic yet ‚Äî only structure.

**Output for this step:**

- Show a patch-like summary of all type/interface changes.
- Explain in 3‚Äì5 bullet points how these types map to the acceptance criteria.

Then continue to STEP 2 automatically.

---

## 2Ô∏è‚É£ STEP 2 ‚Äî TEST (Write Tests for Expected Behavior)

Goal: Encode the expected behavior in tests before coding the implementation.

1. Detect the existing test stack (e.g. Jest, Vitest, Playwright, etc.) from the repo.
2. Add or update unit tests (and integration tests if appropriate) that cover:
   - Happy path
   - Important edge cases
   - Failure/validation scenarios (if relevant)
3. Put tests in the correct location (same pattern as existing tests).
4. Run the test suite for the affected area.

**Expected state after this step:**
- New tests should FAIL because the implementation doesn‚Äôt exist yet.

**Output for this step:**

- List created/modified test files.
- Paste or summarize the key test cases (names + what they assert).
- Show the failing test output (summarized).

Then continue to STEP 3 automatically.

---

## 3Ô∏è‚É£ STEP 3 ‚Äî CODE (Make the Tests Pass)

Goal: Implement the feature logic so all the new tests pass.

1. Implement only what is necessary to satisfy the tests and acceptance criteria.
2. Keep the code aligned with existing architecture (layers, patterns, error handling).
3. Avoid over-engineering or extra features not in the acceptance criteria.
4. Run the tests again until:
   - All new tests pass.
   - No previously passing tests are broken.

**Output for this step:**

- List all modified implementation files.
- Summarize the main logic changes in 3‚Äì7 bullets.
- Provide a short explanation of any trade-offs or important decisions.

Then continue to STEP 4 automatically.

---

## 4Ô∏è‚É£ STEP 4 ‚Äî DOCUMENT (README / docs/)

Goal: Update the documentation so the feature is discoverable and usable.

1. Check for:
   - `README.md`
   - `docs/` folder
   - Any existing documentation structure (e.g. `docs/features`, `docs/api`, etc.).
2. Choose the most appropriate place to document this feature:
   - If the project uses a docs site: add or update a page in `docs/`.
   - If not: extend `README.md` with a new section.
3. The documentation MUST include:
   - **Feature name**
   - **What it does** and **when to use it**
   - **API / interface details** (props, params, return types)
   - **Usage example(s)** (code snippets or CLI commands)
   - Any **limitations / caveats** the user should know.
4. Follow the existing style: headings, tone, formatting.

**Output for this step:**

- Show the added/modified doc sections (or a concise diff-style summary).
- Confirm where the docs live (e.g. `docs/feature-{{slug}}.md` or `README.md#new-feature`).

Then continue to STEP 5 automatically.

---

## 5Ô∏è‚É£ STEP 5 ‚Äî PREVIEW (Run & Screenshot)

Goal: Validate visually that the feature works as intended and capture a screenshot.

1. Detect the correct preview/dev command (e.g. `npm run dev`, `npm run preview`, `pnpm dev`, or framework-specific command).
2. Launch the browser preview for the relevant route / screen where the feature appears.
3. Interact with the UI (if applicable) to demonstrate the expected behavior.
4. Capture a screenshot of the feature in action using the available tooling in this environment.
5. Save or reference the screenshot according to repo conventions. If none exist:
   - Suggest a path like `docs/assets/{{feature_slug}}-preview.png`.

**Output for this step:**

- Confirm the preview command used.
- Describe where in the app the feature can be seen (URL/route, navigation path).
- Attach or reference the screenshot (file path or embedded, depending on capabilities).

---

## ‚úÖ FINAL OUTPUT FORMAT

At the very end, respond with:

1. **Summary**
   - 3‚Äì5 bullets summarizing what was implemented.
2. **Files Changed**
   - Grouped by: types, tests, implementation, docs, other.
3. **Test Status**
   - Command(s) run and final status (all green / remaining issues).
4. **Docs**
   - Where to read about the feature (paths, sections).
5. **Preview**
   - How to run the preview and where to see the feature.
   - Screenshot reference.
6. **Suggested Commit Message**
   - A single line in conventional-commits style, e.g.  
     `feat: add {{feature_name}} with tests and docs`
7. **Follow-ups**
   - Any TODOs, tech debt, or nice-to-have improvements (max 5 bullets).
